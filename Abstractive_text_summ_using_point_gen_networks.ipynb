{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14353,"status":"ok","timestamp":1693740089566,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"},"user_tz":-330},"id":"3vJVlfJZE8pF","outputId":"02e41bd4-e48b-4ade-92bb-bb613e7bb6f4"},"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","Generated Summary  : Once upon a sweltering day, a thirsty crow was on a mission to find water. the crow flew towards the village and saw a pot in a courtyard. after a long search, it saw only a tiny bit of water at the bottom. after a lot of hard work, the crow could drink the water.\n"]}],"source":["import torch\n","import transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import sentencepiece\n","\n","model = \"t5-small\"\n","tokenizer = T5Tokenizer.from_pretrained(model)\n","model_1 = T5ForConditionalGeneration.from_pretrained(model)\n","input_text = \"\"\" Once upon a sweltering day, a very thirsty crow was on a mission to find water. The blazing sun had made it incredibly thirsty, and its wings felt heavy from flying for so long. After a long search, it saw a small village. The crow flew towards the village and saw a pot in a courtyard. It was so excited, but when it looked inside, it saw only a tiny bit of water at the bottom. The crow didn't give up. It had a smart idea. It started picking up small stones and dropping them into the pot, one by one. As it dropped more stones, the water level slowly rose. Finally, after a lot of hard work, the crow could drink the water. It was so happy and flew away, leaving behind a lesson for everyone. The lesson was about not giving up and finding clever ways to solve problems, just like the crow did. The people in the village were amazed by the clever crow and never forgot the story of the thirsty crow. \"\"\"\n","input_ids = tokenizer.encode(\"sumarize : \" + input_text, return_tensors = 'pt' , max_length = 1000 , truncation = True)\n","output = model_1.generate(input_ids, max_length = 150, num_beams = 7 , length_penalty= 2.0 , early_stopping = True )\n","summary = tokenizer.decode(output[0],skip_special_tokens=True)\n","print(\" \")\n","print(\"Generated Summary \", summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufpE6DtYGiRt","outputId":"f8284878-4933-4f14-ec8e-be07a7c86529","executionInfo":{"status":"ok","timestamp":1693739738394,"user_tz":-330,"elapsed":160732,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 1/50, Loss: 2764.97607421875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1, 63])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 2/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 3/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 4/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 5/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 6/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 7/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 8/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 9/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 10/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 11/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 12/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 13/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 14/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 15/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 16/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 17/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 18/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 19/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 20/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 21/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 22/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 23/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 24/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 25/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 26/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 27/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 28/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 29/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 30/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 31/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 32/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 33/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 34/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 35/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 36/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 37/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 38/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 39/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 40/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 41/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 42/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 43/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 44/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 45/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 46/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 47/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 48/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 49/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 50/50, Loss: 2764.97607421875\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import numpy as np\n","import random\n","import pandas as pd\n","import transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import sentencepiece\n","import tensorflow as tf\n","import keras\n","\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","\n","\n","# Input text\n","input_text = \"On a sweltering summer day, a weary and dehydrated crow embarked on a relentless quest for water. With the blazing sun beating down on it, the bird scoured the parched landscape for signs of relief. After what felt like an eternity, it stumbled upon a quaint earthenware pot in the courtyard of a humble village house. Hope turned to disappointment as the crow found only a meager trickle of water at the pot's bottom, far from sufficient to quench its thirst. Yet, the crow refused to yield to despair. Instead, it hatched a clever plan, using its beak to drop small pebbles into the pot, one by one. As each pebble fell, the water level in the pot slowly crept higher. The crow's tenacity knew no bounds, and after relentless effort, the water reached a level where it could drink. With a grateful heart, the crow finally quenched its long-standing thirst. Taking to the sky once more, it left behind a powerful lesson for all who witnessed its remarkable featâ€”a reminder of the indomitable spirit of determination, problem-solving, and the boundless resourcefulness of nature.\"\n","\n","# Output text (target summary)\n","output_text = \"On a scorching summer day, a thirsty crow searched for water. It spotted a village, found a nearly empty pot, and dropped pebbles to raise the water level until it could drink. The story teaches us about determination and clever problem-solving.\"\n","\n","# Tokenize and encode the input text\n","input_encoding = tokenizer(\"summarize: \" + input_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512, add_special_tokens=True)\n","\n","# Tokenize and encode the output text\n","output_encoding = tokenizer(output_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512, add_special_tokens=True)\n","\n","# Access 'input_ids' and 'attention_mask' for input\n","input_ids = input_encoding['input_ids']\n","input_attention_mask = input_encoding['attention_mask']\n","\n","# Access 'input_ids' and 'attention_mask' for output\n","output_ids = output_encoding['input_ids']\n","output_attention_mask = output_encoding['attention_mask']\n","\n","batch_size = 32\n","vocab_size = tokenizer.vocab_size\n","lr = 0.001\n","epochs = 10\n","num_epochs = 50\n","hidden_states = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class PointerGenerator(nn.Module):\n","\n","  def __init__(self,model_name,vocab_size):\n","    super(PointerGenerator, self).__init__()\n","    self.model_name = T5ForConditionalGeneration.from_pretrained(model_name)\n","    self.output_projection = nn.Linear(self.model_name.config.d_model, vocab_size)\n","    self.softmax = nn.Softmax(dim = -1)\n","\n","  def forwardpass(self, input_ids, output_ids, hidden_states):\n","    t5_output = self.model_name(input_ids = input_ids, decoder_input_ids = output_ids)\n","    point_gen = torch.tensor(0.5)  # Replace with your desired value\n","    vocab_dist = torch.ones(vocab_size) / vocab_size  #\n","    return point_gen , vocab_dist\n","\n","from typing import Any\n","input_ids = torch.cat((input_ids,), dim = 0)\n","output_ids = torch.cat((output_ids,), dim = 0)\n","\n","dataset = TensorDataset(input_ids, output_ids)\n","dataloader = DataLoader( dataset, batch_size=32, shuffle=False)\n","\n","vocab_size: Any\n","modelf = PointerGenerator(\"t5-small\",vocab_size)\n","optimizer = optim.Adam(modelf.parameters(), lr=0.001)\n","criterion = nn.L1Loss()\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    modelf.train()\n","\n","    for batch in dataloader:\n","        input_batch, output_batch = batch\n","        input_batch = input_batch.to(device).reshape(1,-1)\n","        output_batch = output_batch.to(device).reshape(1,-1)\n","\n","        optimizer = optim.SGD(modelf.parameters(), lr=0.01)\n","        optimizer.zero_grad()\n","\n","        # Debugging: Check input_batch and output_batch shapes\n","        print(f\"Input Batch Shape: {input_batch.shape}\")\n","        print(f\"Output Batch Shape: {output_batch.shape}\")\n","\n","      # Determine the desired size along dimension 3 (the third dimension)\n","        desired_size = max(input_batch.size(1), output_batch.size(-2))\n","\n","      # Calculate the amount of padding needed for 'a' along dimension 3\n","        padding_size = desired_size - input_batch.size(-2)\n","\n","        from torch.nn.utils.rnn import pad_sequence\n","\n","# Assuming input_batch and output_batch are lists of tensors\n","# Convert them to a list of tensors of the same length by padding the shorter sequences\n","        padded_input_batch = pad_sequence(input_batch, batch_first=True)\n","        padded_output_batch = pad_sequence(output_batch, batch_first=True)\n","        padded_ip_batch = padded_input_batch.reshape(-1,1)\n","\n","\n","        # Forward pass\n","        logits, hidden_states = modelf.forwardpass(input_batch, output_batch, hidden_states)  # Ensure the model returns hidden_states\n","\n","        # Debugging: Check hidden_states\n","        print(f\"Hidden States Shape: {hidden_states.shape}\")\n","\n","        # Assuming logits and output_batch are your tensors\n","        logits = logits.view(-1, 1)  # Reshape to [1, vocab_size]\n","        output_batch = output_batch.view(1, -1)\n","        output_batch = output_batch.to(torch.float32)\n","        logits.requires_grad = True\n","        output_batch.requires_grad = True\n","        # Calculate loss\n","        loss = criterion(logits, output_batch)\n","\n","        # Set requires_grad=True for all model parameters\n","        for param in modelf.parameters():\n","          if param not in modelf.parameters(0):\n","            param.requires_grad = True\n","\n","        # Define the optimizer (e.g., Stochastic Gradient Descent)\n","        optimizer = optim.SGD(modelf.parameters(), lr=0.01)\n","\n","\n","        loss.backward()\n","\n","\n","        # Perform an optimizer step\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n","\n","    torch.save(modelf.state_dict(), \"pointer_generator_model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11979,"status":"ok","timestamp":1693740376268,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"},"user_tz":-330},"id":"gjSJjN73GmOT","outputId":"6a0205a9-a8e7-4fe9-a8aa-3fbcf12ca8d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=b9b07a1ec1e94d60bc328daf19d2c5db388946bb3009b23a2554e5c827cf4c08\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}],"source":["\n","!pip install rouge-score\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":709,"status":"ok","timestamp":1693740763615,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"},"user_tz":-330},"id":"oYkWXSxC3QRc","outputId":"58a8d851-f30c-4c2f-9626-1dbdb4bfb9b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROUGE-1 F1 Score: 0.41237113402061853\n","ROUGE-2 F1 Score: 0.14736842105263157\n","ROUGE-L F1 Score: 0.26804123711340205\n"]}],"source":["from rouge_score import rouge_scorer\n","\n","# Example reference and hypothesis summaries\n","reference_summary = \"On a scorching summer day, a thirsty crow searched for water. It spotted a village, found a nearly empty pot, and dropped pebbles to raise the water level until it could drink. The story teaches us about determination and clever problem-solving.\"\n","hypothesis_summary = \"Once upon a sweltering day, a thirsty crow was on a mission to find water. the crow flew towards the village and saw a pot in a courtyard. after a long search, it saw only a tiny bit of water at the bottom. after a lot of hard work, the crow could drink the water.\"\n","\n","# Initialize the ROUGE scorer\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","\n","# Calculate ROUGE scores\n","scores = scorer.score(reference_summary, hypothesis_summary)\n","\n","# Access individual ROUGE scores\n","rouge1_score = scores['rouge1'].fmeasure\n","rouge2_score = scores['rouge2'].fmeasure\n","rougeL_score = scores['rougeL'].fmeasure\n","\n","# Print ROUGE scores\n","print(f'ROUGE-1 F1 Score: {rouge1_score}')\n","print(f'ROUGE-2 F1 Score: {rouge2_score}')\n","print(f'ROUGE-L F1 Score: {rougeL_score}')\n","\n","\n"]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","nltk.download('punkt')\n","\n","# Reference and generated summaries\n","reference_summary = \"On a scorching summer day, a thirsty crow searched for water. It spotted a village, found a nearly empty pot, and dropped pebbles to raise the water level until it could drink. The story teaches us about determination and clever problem-solving.\"\n","generated_summary = \"Once upon a sweltering day, a thirsty crow was on a mission to find water. the crow flew towards the village and saw a pot in a courtyard. after a long search, it saw only a tiny bit of water at the bottom. after a lot of hard work, the crow could drink the water.\"\n","# Tokenize the reference and generated summaries\n","reference_tokens = word_tokenize(reference_summary.lower())\n","generated_tokens = word_tokenize(generated_summary.lower())\n","\n","# Calculate BLEU score (you can choose n-gram order, e.g., 1 for unigram, 2 for bigram, etc.)\n","bleu_score = sentence_bleu([reference_tokens], generated_tokens, weights=(1, 0, 0, 0))\n","\n","print(\"BLEU Score:\", bleu_score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oh9MyYX1ztuJ","executionInfo":{"status":"ok","timestamp":1693740747361,"user_tz":-330,"elapsed":779,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"}},"outputId":"853b9b10-6067-4c45-eda3-003806e28c07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score: 0.4032258064516129\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1S24uxcFtX0CsP4ABXSRDidlSZfMQ1Ywn","timestamp":1693748550860}],"authorship_tag":"ABX9TyMUiDnf5oKsSbVxhKQ1UncD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}