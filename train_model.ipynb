{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAd8L5QrF/NNkk0aUcZk/1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c76b284e98df414588a7e891c5b34c03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7db0d95e9cc74abf938c85965a6f32a8","IPY_MODEL_919d45b8be124144ac315f1b8bbb29f9","IPY_MODEL_d2f795dc86b24efab6108bf14ecd3945"],"layout":"IPY_MODEL_0165e32be56440e19671eb0345e00e51"}},"7db0d95e9cc74abf938c85965a6f32a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07d97a84c2014de58fca2c0e0a9fceac","placeholder":"​","style":"IPY_MODEL_edfa8dd7959c4e9194fd48fbb038ea4a","value":"Downloading (…)lve/main/config.json: 100%"}},"919d45b8be124144ac315f1b8bbb29f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73982ee630f44b8b19d9ab3a890f145","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_996969859100424ab30b40e1cca60687","value":1206}},"d2f795dc86b24efab6108bf14ecd3945":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20ebc1472be84a7b88f8e3d696650bd3","placeholder":"​","style":"IPY_MODEL_1786a67a50814699b1ab8d5921d4ff26","value":" 1.21k/1.21k [00:00&lt;00:00, 94.3kB/s]"}},"0165e32be56440e19671eb0345e00e51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d97a84c2014de58fca2c0e0a9fceac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfa8dd7959c4e9194fd48fbb038ea4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f73982ee630f44b8b19d9ab3a890f145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996969859100424ab30b40e1cca60687":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20ebc1472be84a7b88f8e3d696650bd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1786a67a50814699b1ab8d5921d4ff26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75821715ea95462dbf28ec57857912ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb2d356c9efc48dc8386d8e0138d83ff","IPY_MODEL_b320eb50a7ed416cb3d6f7828ecd622b","IPY_MODEL_ffdf3509aa3f4bf7ba11da3c947ab422"],"layout":"IPY_MODEL_c1c9d093e4724fadb7985a1b5947992d"}},"cb2d356c9efc48dc8386d8e0138d83ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55ae7837739a42aba80ece46b698404f","placeholder":"​","style":"IPY_MODEL_7935912c44ab49129eb94098d5fe55af","value":"Downloading model.safetensors: 100%"}},"b320eb50a7ed416cb3d6f7828ecd622b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_984863e7ab8148829e8d39834a4d1a16","max":242043056,"min":0,"orientation":"horizontal","style":"IPY_MODEL_044faa42f0834073ac7f568d4a5d4b73","value":242043056}},"ffdf3509aa3f4bf7ba11da3c947ab422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e800db7e8efe456ca566686ff7eb91f8","placeholder":"​","style":"IPY_MODEL_1eae3b3751a44b98a4e095d7e5f69b65","value":" 242M/242M [00:00&lt;00:00, 432MB/s]"}},"c1c9d093e4724fadb7985a1b5947992d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ae7837739a42aba80ece46b698404f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7935912c44ab49129eb94098d5fe55af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"984863e7ab8148829e8d39834a4d1a16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"044faa42f0834073ac7f568d4a5d4b73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e800db7e8efe456ca566686ff7eb91f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eae3b3751a44b98a4e095d7e5f69b65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a497d9b0899422d89d41906c907e6a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24a1617cd10e4c5e855d04266fa49c93","IPY_MODEL_d296dbf414e6413a9000e8d17b3c2680","IPY_MODEL_8d906a953f314c0b9a35ec0c146b677e"],"layout":"IPY_MODEL_6228407c7c1d4849a0d0045538a579e7"}},"24a1617cd10e4c5e855d04266fa49c93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72686e7d882e4f2ca3757b5fd8cbd58e","placeholder":"​","style":"IPY_MODEL_582b2c0ebe67477dae2d9419d8552b10","value":"Downloading (…)neration_config.json: 100%"}},"d296dbf414e6413a9000e8d17b3c2680":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_978a1ef52f074a68ae81412346ebafef","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17b11de84fd14e60972815d71ec91a2f","value":147}},"8d906a953f314c0b9a35ec0c146b677e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c002f6d175141babff9f09c3fddf1b6","placeholder":"​","style":"IPY_MODEL_909ea8da486043a3aab691f6d68c39ae","value":" 147/147 [00:00&lt;00:00, 10.2kB/s]"}},"6228407c7c1d4849a0d0045538a579e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72686e7d882e4f2ca3757b5fd8cbd58e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"582b2c0ebe67477dae2d9419d8552b10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"978a1ef52f074a68ae81412346ebafef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17b11de84fd14e60972815d71ec91a2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c002f6d175141babff9f09c3fddf1b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"909ea8da486043a3aab691f6d68c39ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-0RvOZSEkli","executionInfo":{"status":"ok","timestamp":1693745084278,"user_tz":-330,"elapsed":14741,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"}},"outputId":"351c8fad-c6c5-4021-cdc0-75a0d3d7bbad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ASy-4vXawxQa","executionInfo":{"status":"ok","timestamp":1693745090442,"user_tz":-330,"elapsed":2788,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import numpy as np\n","import random\n","import pandas as pd\n","import transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import sentencepiece\n","import tensorflow as tf\n","import keras\n"]},{"cell_type":"code","source":[],"metadata":{"id":"HR_pFuT9FI6w"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c76b284e98df414588a7e891c5b34c03","7db0d95e9cc74abf938c85965a6f32a8","919d45b8be124144ac315f1b8bbb29f9","d2f795dc86b24efab6108bf14ecd3945","0165e32be56440e19671eb0345e00e51","07d97a84c2014de58fca2c0e0a9fceac","edfa8dd7959c4e9194fd48fbb038ea4a","f73982ee630f44b8b19d9ab3a890f145","996969859100424ab30b40e1cca60687","20ebc1472be84a7b88f8e3d696650bd3","1786a67a50814699b1ab8d5921d4ff26","75821715ea95462dbf28ec57857912ff","cb2d356c9efc48dc8386d8e0138d83ff","b320eb50a7ed416cb3d6f7828ecd622b","ffdf3509aa3f4bf7ba11da3c947ab422","c1c9d093e4724fadb7985a1b5947992d","55ae7837739a42aba80ece46b698404f","7935912c44ab49129eb94098d5fe55af","984863e7ab8148829e8d39834a4d1a16","044faa42f0834073ac7f568d4a5d4b73","e800db7e8efe456ca566686ff7eb91f8","1eae3b3751a44b98a4e095d7e5f69b65","9a497d9b0899422d89d41906c907e6a2","24a1617cd10e4c5e855d04266fa49c93","d296dbf414e6413a9000e8d17b3c2680","8d906a953f314c0b9a35ec0c146b677e","6228407c7c1d4849a0d0045538a579e7","72686e7d882e4f2ca3757b5fd8cbd58e","582b2c0ebe67477dae2d9419d8552b10","978a1ef52f074a68ae81412346ebafef","17b11de84fd14e60972815d71ec91a2f","8c002f6d175141babff9f09c3fddf1b6","909ea8da486043a3aab691f6d68c39ae"]},"id":"ufpE6DtYGiRt","outputId":"12e4f611-b78e-4730-a259-2a7f33c6a16b","executionInfo":{"status":"ok","timestamp":1693745465969,"user_tz":-330,"elapsed":104027,"user":{"displayName":"Vansh Julka","userId":"04525971208789675291"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76b284e98df414588a7e891c5b34c03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75821715ea95462dbf28ec57857912ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a497d9b0899422d89d41906c907e6a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 1/50, Loss: 2764.97607421875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1, 63])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 2/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 3/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 4/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 5/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 6/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 7/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 8/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 9/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 10/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 11/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 12/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 13/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 14/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 15/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 16/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 17/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 18/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 19/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 20/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 21/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 22/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 23/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 24/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 25/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 26/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 27/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 28/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 29/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 30/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 31/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 32/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 33/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 34/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 35/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 36/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 37/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 38/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 39/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 40/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 41/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 42/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 43/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 44/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 45/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 46/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 47/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 48/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 49/50, Loss: 2764.97607421875\n","Input Batch Shape: torch.Size([1, 283])\n","Output Batch Shape: torch.Size([1, 63])\n","Hidden States Shape: torch.Size([32100])\n","Epoch 50/50, Loss: 2764.97607421875\n"]}],"source":["\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","input_text = \"On a sweltering summer day, a weary and dehydrated crow embarked on a relentless quest for water. With the blazing sun beating down on it, the bird scoured the parched landscape for signs of relief. After what felt like an eternity, it stumbled upon a quaint earthenware pot in the courtyard of a humble village house. Hope turned to disappointment as the crow found only a meager trickle of water at the pot's bottom, far from sufficient to quench its thirst. Yet, the crow refused to yield to despair. Instead, it hatched a clever plan, using its beak to drop small pebbles into the pot, one by one. As each pebble fell, the water level in the pot slowly crept higher. The crow's tenacity knew no bounds, and after relentless effort, the water reached a level where it could drink. With a grateful heart, the crow finally quenched its long-standing thirst. Taking to the sky once more, it left behind a powerful lesson for all who witnessed its remarkable feat—a reminder of the indomitable spirit of determination, problem-solving, and the boundless resourcefulness of nature.\"\n","output_text = \"On a scorching summer day, a thirsty crow searched for water. It spotted a village, found a nearly empty pot, and dropped pebbles to raise the water level until it could drink. The story teaches us about determination and clever problem-solving.\"\n","input_encoding = tokenizer(\"summarize: \" + input_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512, add_special_tokens=True)\n","output_encoding = tokenizer(output_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512, add_special_tokens=True)\n","input_ids = input_encoding['input_ids']\n","input_attention_mask = input_encoding['attention_mask']\n","output_ids = output_encoding['input_ids']\n","output_attention_mask = output_encoding['attention_mask']\n","\n","batch_size = 32\n","vocab_size = tokenizer.vocab_size\n","lr = 0.001\n","epochs = 10\n","num_epochs = 50\n","hidden_states = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class PointerGenerator(nn.Module):\n","\n","  def __init__(self,model_name,vocab_size):\n","    super(PointerGenerator, self).__init__()\n","    self.model_name = T5ForConditionalGeneration.from_pretrained(model_name)\n","    self.output_projection = nn.Linear(self.model_name.config.d_model, vocab_size)\n","    self.softmax = nn.Softmax(dim = -1)\n","\n","  def forwardpass(self, input_ids, output_ids, hidden_states):\n","    t5_output = self.model_name(input_ids = input_ids, decoder_input_ids = output_ids)\n","    point_gen = torch.tensor(0.5)  # Replace with your desired value\n","    vocab_dist = torch.ones(vocab_size) / vocab_size  #\n","    return point_gen , vocab_dist\n","\n","from typing import Any\n","input_ids = torch.cat((input_ids,), dim = 0)\n","output_ids = torch.cat((output_ids,), dim = 0)\n","\n","dataset = TensorDataset(input_ids, output_ids)\n","dataloader = DataLoader( dataset, batch_size=32, shuffle=False)\n","\n","vocab_size: Any\n","modelf = PointerGenerator(\"t5-small\",vocab_size)\n","optimizer = optim.Adam(modelf.parameters(), lr=0.001)\n","criterion = nn.L1Loss()\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    modelf.train()\n","\n","    for batch in dataloader:\n","        input_batch, output_batch = batch\n","        input_batch = input_batch.to(device).reshape(1,-1)\n","        output_batch = output_batch.to(device).reshape(1,-1)\n","        optimizer = optim.SGD(modelf.parameters(), lr=0.01)\n","        optimizer.zero_grad()\n","        print(f\"Input Batch Shape: {input_batch.shape}\")\n","        print(f\"Output Batch Shape: {output_batch.shape}\")\n","        desired_size = max(input_batch.size(1), output_batch.size(-2))\n","        padding_size = desired_size - input_batch.size(-2)\n","        from torch.nn.utils.rnn import pad_sequence\n","        padded_input_batch = pad_sequence(input_batch, batch_first=True)\n","        padded_output_batch = pad_sequence(output_batch, batch_first=True)\n","        padded_ip_batch = padded_input_batch.reshape(-1,1)\n","        logits, hidden_states = modelf.forwardpass(input_batch, output_batch, hidden_states)  # Ensure the model returns hidden_states\n","        print(f\"Hidden States Shape: {hidden_states.shape}\")\n","        logits = logits.view(-1, 1)\n","        output_batch = output_batch.view(1, -1)\n","        output_batch = output_batch.to(torch.float32)\n","        logits.requires_grad = True\n","        output_batch.requires_grad = True\n","        loss = criterion(logits, output_batch)\n","        for param in modelf.parameters():\n","          if param not in modelf.parameters(0):\n","            param.requires_grad = True\n","        optimizer = optim.SGD(modelf.parameters(), lr=0.01)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n","    torch.save(modelf.state_dict(), \"pointer_generator_model.pth\")"]}]}